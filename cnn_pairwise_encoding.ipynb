{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN with Pairwise encoding for recommendation"
      ],
      "metadata": {
        "id": "U3sn8fbgcMKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to study whether the algorithm proposed in *CosRec: 2D Convolutional Neural Networks for Sequential Recommendation* (Yan et al) can be efficiently applied to sequential recommendation."
      ],
      "metadata": {
        "id": "2avcXTkmcS05"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clnpei9Wf4Zv"
      },
      "source": [
        "from keras.layers import Dense, Activation, Input, MaxPooling2D, Embedding, Conv2D, Reshape, Permute, Dropout, RepeatVector, Concatenate, BatchNormalization, AveragePooling2D\n",
        "from keras.models import load_model, Model, Sequential\n",
        "from keras.utils import Sequence\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # Il faut pouvoir lire les fichiers CSV du Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h1gJHtXDfGup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtvBDYucgq25"
      },
      "source": [
        "# Nombre de valeurs dans le dictionnaire + la valeur vide\n",
        "d = 14370 + 1 # 1 catégories supplémentaires : une <EOS>\n",
        "# Taille de l'input\n",
        "Tx = 64\n",
        "# Taille de l'output\n",
        "Ty = 16\n",
        "# Dimension de l'embedding\n",
        "n_e = 64\n",
        "# Mini-batch size\n",
        "m = 256\n",
        "\n",
        "# Paramètre du premier CONV2D\n",
        "n_k_1 = 2\n",
        "n_k_2 = 3\n",
        "n_k_3 = 1\n",
        "n_k_4 = 3\n",
        "\n",
        "n_f_1 = 1.75 * n_e\n",
        "n_f_2 = 1.5 * n_e\n",
        "n_f_3 = 1.25 * n_e\n",
        "n_f_4 = n_e\n",
        "\n",
        "n_ap_1 = (4, 2) # on réduit le nombre de lignes lors des average poolings\n",
        "n_ap_2 = (8, 1) # on réduit le nombre de lignes lors des average poolings\n",
        "\n",
        "# Paramêtres du FC network\n",
        "n_fc = 128\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIyllHQxgc3Q"
      },
      "source": [
        "# def CNNmodel():\n",
        "#   inpt = Input(shape=(Tx,))\n",
        "#   # Embedding\n",
        "#   embedding = Embedding(input_dim=d , output_dim=n_e, input_length=Tx)\n",
        "#   # First layer, we embedd the input sequence to get a (Tx , n_e) picture\n",
        "#   x = embedding(inpt)\n",
        "\n",
        "#   x = Reshape(target_shape=(Tx, 1, n_e))(x)\n",
        "\n",
        "#   x = Concatenate(axis = 2)([x] * Tx)\n",
        "\n",
        "# # x = RepeatVector(Tx)(x) # On est censé obtenir ensuite du (Tx, Tx, n_e)\n",
        "# # Dans cette nouvelle forme, quand on représente x comme un carré Tx x Tx de profondeur n_e, chaque colonne du carré représente un même produit\n",
        "#   # xprime = K.transpose(x)\n",
        "#   # xprime = K.reverse(xprime, axes = 1) # rotation de 90 degrés dans le sens des aiguilles d'une montre par transposition puis symétrie\n",
        "#   # il ne reste plus maintenant qu'à concaténer x et xprime selon la profondeur (3e dimension)\n",
        "\n",
        "#   # xprime = Permute((1,2), input_shape=(Tx, Tx, n_e))(x)\n",
        "#   xprime = K.permute_dimensions(x, (0, 2, 1, 3))\n",
        "\n",
        "#   x = Concatenate(axis = 3)([x, xprime]) # en théorie ici on a précisément ce qu'on veut, et x est de dimension (T_x, T_x, 2 * n_e)\n",
        "# # De plus, quand on regarde x de face avec 2*n_e en profondeur, la colonne détermine les n_e premières composantes (le premier produit en venant de nous), et la ligne détermine les n_e suivantes\n",
        "\n",
        "#   print(tf.shape(x))\n",
        "#     # A Conv2D network\n",
        "#   x = Conv2D(filters=n_f_1 , kernel_size= n_k_1, padding = \"valid\", strides = n_k_1, activation=\"relu\")(x)\n",
        "\n",
        "#   x = Conv2D(filters=n_f_2 , kernel_size= n_k_2, padding = \"same\", activation=\"relu\")(x)\n",
        "\n",
        "#   x = BatchNormalization(axis = (1, 2))(x)\n",
        "#   x = AveragePooling2D(pool_size=n_ap_1, padding = \"valid\", strides = n_ap_1)(x)\n",
        "#   x = Conv2D(filters=n_f_3 , kernel_size= n_k_3, padding = \"same\", activation=\"relu\")(x)\n",
        "\n",
        "#   x = Conv2D(filters=n_f_4 , kernel_size= n_k_4, padding = \"same\", activation=\"relu\")(x)\n",
        "\n",
        "#   x = BatchNormalization(axis = (1, 2))(x)\n",
        "#   x = AveragePooling2D(pool_size=n_ap_2, padding = \"valid\", strides = n_ap_2)(x)\n",
        "\n",
        "\n",
        "# # Si mes calculs sont bons on doit arriver à (1, Ty, n_e) ici\n",
        "#   x = Reshape(target_shape=(Ty, n_e))(x)\n",
        "#   # A FC network\n",
        "#   x = Dense(n_fc, activation=\"relu\")(x)\n",
        "#   x = Dropout(0.2)(x)\n",
        "#   x = Dense(d , activation=\"softmax\")(x)\n",
        "\n",
        "#   model = Model(inputs = inpt , outputs = x)\n",
        "#   return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CNNmodel()\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\", metrics=\"categorical_accuracy\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jIK6wnxLfIPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COoQ2OX4vgOC"
      },
      "source": [
        "# model.save(\"PairwiseEncodingCNN_save/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suhucVKYvF84"
      },
      "source": [
        "folder = \"/content/drive/MyDrive/PSC Recommandation séquentielle/Données/DataTables/\"\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "  def __init__(self , nb_lines, X_path, Y_path):\n",
        "    self.X_path = X_path\n",
        "    self.X_reader = csv.reader(open(folder + X_path , \"r\"))\n",
        "    self.Y_path = Y_path\n",
        "    self.Y_reader = csv.reader(open(folder + Y_path , \"r\"))\n",
        "    self.nb_lines = nb_lines\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil(self.nb_lines/m)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    X1 = []\n",
        "    Y = []\n",
        "    for i in range(m):\n",
        "      x,y = self.getNextSample()\n",
        "      x = [int(i) for i in x]\n",
        "      y = [[int(i)] for i in y]\n",
        "      X1.append(x)\n",
        "      Y.append(y)\n",
        "    X1 = np.array(X1)\n",
        "    return np.array(X1) , np.array(Y)\n",
        "\n",
        "  def getNextSample(self):\n",
        "    x = next(self.X_reader , None)\n",
        "    y = next(self.Y_reader , None)\n",
        "    if x is None:\n",
        "      self.X_reader = csv.reader(open(folder + self.X_path , \"r\"))\n",
        "      self.Y_reader = csv.reader(open(folder + self.Y_path , \"r\"))\n",
        "      x = next(self.X_reader , None)\n",
        "      y = next(self.Y_reader , None)\n",
        "    return x , y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzBJ6aTal-mN"
      },
      "source": [
        "model = load_model(\"/content/drive/MyDrive/PSC Recommandation séquentielle/Modèles/CNN/CNN Pairwise Encoding/PairwiseEncodingCNN_save/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_gen = DataGenerator(3705954\n",
        "#                           , \"./s2_X_train.csv\"\n",
        "#                           ,\"./s2_Y_train.csv\")\n",
        "# model.fit(train_gen , epochs=1, verbose = 1)\n",
        "\n",
        "# model.save(\"PairwiseEncodingCNN_save/\")"
      ],
      "metadata": {
        "id": "5nHPmv84cg9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WflliAY5H7ah"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}