{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Surprise for recommendation\n",
        "The goal of this notebook is to study whether the Python module *Surprise* can be efficiently applied for the e-commerce platform."
      ],
      "metadata": {
        "id": "N7NqdjTAdcJS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o72Ghiv4wPEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cab524f-a170-4164-bb58-be5dd63a5b77"
      },
      "source": [
        "# Install a pip package in the current Jupyter kernel\n",
        "import sys\n",
        "!{sys.executable} -m pip install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r25VIrciFf_3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPIxs4EFw3fy"
      },
      "source": [
        "!{sys.executable} -m pip install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYsEH6yBxM6g"
      },
      "source": [
        "!{sys.executable} -m pip install surprise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtR-2mhExdJX"
      },
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import BaselineOnly\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "file_path = '/content/drive/MyDrive/PSC Recommandation séquentielle/Surprise/results-20201202-150338_supprimer_1re_donnee.csv' #file_path = '/content/drive/MyDrive/PSC Recommandation séquentielle/Surprise/results-20201202-150338.csv'\n",
        "# As we're loading a custom dataset, we need to define a reader\n",
        "reader = Reader(skip_lines = 1, sep=',')\n",
        "data = Dataset.load_from_file(file_path, reader=reader)\n",
        "algo = SVD() # SIngular value decomposition\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "#RSME : Root-mean-square-error\n",
        "#MAE : Mean absolute error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 10% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=.1)\n",
        "# We'll use the famous SVD algorithm.\n",
        "algo = SVD()\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "id": "O4M_XP5qe2o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import KNNBasic\n",
        "from surprise import Dataset\n",
        "# Obviously, we could also simply fit our algorithm to the whole dataset, rather than running cross-validation.\n",
        "# Retrieve the trainset.\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "# Build an algorithm, and train it.\n",
        "algo = KNNBasic()\n",
        "algo.fit(trainset)\n",
        "uid = str(1003460133)\n",
        "iid = str(5000159461849) #iid = str(3276550272403)\n",
        "# get a prediction for specific users and items.\n",
        "pred = algo.predict(uid, iid, r_ui=None, verbose=True)"
      ],
      "metadata": {
        "id": "OnzNzUGje3zX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}