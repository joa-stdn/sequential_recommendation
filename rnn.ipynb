{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHNZaF_T01Y1"
      },
      "source": [
        "# Recurrent Neural Networks for sequential recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIIDjEYq01Us"
      },
      "source": [
        "The purpose of this notebook is to create an RNN architecture capable of addressing our problem in a more precise and computationally efficient manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoPrc58u0shD"
      },
      "source": [
        "from keras.layers import Dense, Activation, Input, LSTM, Embedding, TimeDistributed\n",
        "from keras.models import load_model, Model\n",
        "from keras.utils import Sequence\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_-2yIcsqOAx",
        "outputId": "3b494854-527d-43cb-ada1-96420e9f8487"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoF1OB5H1U7D"
      },
      "source": [
        "## Designing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-adoDtv91kI-"
      },
      "source": [
        "# Nombre de valeurs dans le dictionnaire + la valeur vide\n",
        "d = 14370 + 1 # 1 catégories supplémentaires : une <EOS>\n",
        "# Taille de l'input\n",
        "Tx = 64\n",
        "# Taille de l'output\n",
        "Ty = 16\n",
        "# Batch Size\n",
        "m = 1500\n",
        "# Dimension de l'état caché du LSTM de l'encodeur\n",
        "n_e = 256\n",
        "# Dimension de l'état caché du LSTM du décodeur\n",
        "n_d = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL_rklfL1SAT"
      },
      "source": [
        "def RNN_model_with_embeddings():\n",
        "    emb_model = load_model(\"/content/drive/MyDrive/PSC Recommandation séquentielle/Modèles/RNN/Embbeding_64 save\")\n",
        "    embedding_layer = Embedding(d , 64, weights = [emb_model.get_weights()[0]], trainable = True)\n",
        "\n",
        "    encoder_inputs = Input(shape=(Tx), dtype='int32',)\n",
        "    encoder_LSTM = LSTM(n_e, return_state=True, name=\"encoder_LSTM\")\n",
        "    embedded_encoder_inputs = embedding_layer(encoder_inputs)\n",
        "    encoder_outputs, state_h, state_c = encoder_LSTM(embedded_encoder_inputs)\n",
        "\n",
        "    decoder_inputs = Input(shape=(Ty), dtype='int32',)\n",
        "    decoder_LSTM = LSTM(n_d, return_state=True, return_sequences=True, name=\"decoder_LSTM\")\n",
        "    embedded_decoder_inputs = embedding_layer(decoder_inputs)\n",
        "    decoder_outputs, _, _ = decoder_LSTM(embedded_decoder_inputs, initial_state=[state_h, state_c])\n",
        "\n",
        "    outputs = TimeDistributed(Dense(d, activation='softmax'))(decoder_outputs)\n",
        "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = RNN_model_with_embeddings()\n",
        "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics= \"accuracy\")\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "OrvviQ81eOkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save(\"/content/drive/MyDrive/PSC Recommandation séquentielle/Modèles/RNN/RNN_3_save\")"
      ],
      "metadata": {
        "id": "yGQGGFwteQzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfuB48kw8k2a"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_UiFMoy3jiY"
      },
      "source": [
        "folder = \"/content/drive/MyDrive/PSC Recommandation séquentielle/Données/DataTables/\"\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "  def __init__(self , nb_lines, X_path, Y_path):\n",
        "    self.X_path = X_path\n",
        "    self.X_reader = csv.reader(open(folder + X_path , \"r\"))\n",
        "    self.Y_path = Y_path\n",
        "    self.Y_reader = csv.reader(open(folder + Y_path , \"r\"))\n",
        "    self.nb_lines = nb_lines\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil(self.nb_lines/m)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    Y = []\n",
        "    for i in range(m):\n",
        "      x,y = self.getNextSample()\n",
        "      x = [int(i) for i in x]\n",
        "      y = [int(i) for i in y]\n",
        "      X1.append(x)\n",
        "      X2.append([0] + y[0:Ty-1])\n",
        "      Y.append(y)\n",
        "    X1 = np.array(X1)\n",
        "    X2 = np.array(X2)\n",
        "    return [np.array(X1), np.array(X2)] , np.array(Y)\n",
        "\n",
        "  def getNextSample(self):\n",
        "    x = next(self.X_reader , None)\n",
        "    y = next(self.Y_reader , None)\n",
        "    if x is None:\n",
        "      self.X_reader = csv.reader(open(folder + self.X_path , \"r\"))\n",
        "      self.Y_reader = csv.reader(open(folder + self.Y_path , \"r\"))\n",
        "      x = next(self.X_reader , None)\n",
        "      y = next(self.Y_reader , None)\n",
        "    return x , y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"/content/drive/MyDrive/PSC Recommandation séquentielle/Modèles/RNN/RNN_3_save\")\n",
        "model.compile(optimizer=\"Adamax\", loss=\"sparse_categorical_crossentropy\", metrics= \"accuracy\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XIAmf_uXew9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/PSC Recommandation séquentielle/Modèles/RNN/RNN model 3_64 save/saved_model.pb\",\n",
        "#                             monitor='loss', verbose=1, save_weights_only = True,\n",
        "#                             save_best_only=False, mode='auto', save_freq=1000)\n",
        "\n",
        "train_gen = DataGenerator(3705954\n",
        "                          , \"reversed_X_train.csv\"\n",
        "                          ,\"Y_train.csv\")\n",
        "model.fit(train_gen , epochs=4, verbose = 1, #callbacks=[checkpoint]\n",
        "          )\n",
        "\n",
        "model.save(\"/content/drive/MyDrive/PSC Recommandation séquentielle/Modèles/RNN/RNN_3_save\")\n"
      ],
      "metadata": {
        "id": "uIgPOIYSeVug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8USfHF4CBA4"
      },
      "source": [
        "### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObxjR45Ycrij"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hj9JQTTcuEh"
      },
      "source": [
        "### Beam search inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(input_sequence , k):\n",
        "  # On utilise une entrée bidon pour nourir le modèle et obtenir le premier item\n",
        "  X2 = [0]*Ty\n",
        "  input_sequence = np.array([input_sequence])\n",
        "  # On cherche à savoir les différentes probabilité que le premier item soit acheté\n",
        "  Y = model.predict([input_sequence , np.array([X2])] , batch_size=1)\n",
        "  Y = [(Y[0][0][i] , i) for i in range(2,d)]\n",
        "  Y.sort(reverse = True)\n",
        "\n",
        "  K_best_candidates = []\n",
        "  for i in range(k):\n",
        "    score , item = Y[i]\n",
        "    K_best_candidates.append((score , [item]))\n",
        "\n",
        "  for i in range(1, Ty):\n",
        "    next_best_candidates = []\n",
        "    for candidat in K_best_candidates :\n",
        "      score , X2 = candidat\n",
        "      X = X2.copy() + [0]*(Ty - len(X2))\n",
        "      Y = model.predict( [input_sequence , np.array([X])] , batch_size=1)\n",
        "      Y = [(Y[0][i][j] , j) for j in range(1, d)]\n",
        "      Y.sort(reverse = True)\n",
        "      for j in range(k):\n",
        "        proba , item = Y[j]\n",
        "        next_best_candidates.append((score*proba , X2.copy() + [item]))\n",
        "\n",
        "    next_best_candidates.sort(reverse= True)\n",
        "    K_best_candidates = next_best_candidates[0:k]\n",
        "\n",
        "  _ , infered_sequence = K_best_candidates[0]\n",
        "\n",
        "  return [item for item in infered_sequence]\n",
        "\n",
        "\n",
        "\n",
        "with open(folder + \"Y_dev.csv\" , \"r\") as csvfile:\n",
        "  r = csv.reader(csvfile)\n",
        "  for i in range(0) : next(r)\n",
        "  T = [int(i) for i in next(r)]\n",
        "  print(\"Séquence de référence: \")\n",
        "  print(T)\n",
        "\n",
        "with open(folder + \"reversed_X_dev.csv\" , \"r\") as csvfile:\n",
        "  r = csv.reader(csvfile)\n",
        "  for i in range(0) : next(r)\n",
        "  T = beam_search([int(i) for i in next(r)] , 10)\n",
        "  print(\"Séquence inférée: \")\n",
        "  print(T)"
      ],
      "metadata": {
        "id": "CyXuwBNvegp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ha-LWlR6uO-"
      },
      "source": [
        "### Auto-excitement phenomenon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZfHEEqAebtZ"
      },
      "source": [
        "  def proba_a_posteriori(input_sequence , k):\n",
        "    X = np.array([input_sequence])\n",
        "    Y = beam_search(input_sequence , k)\n",
        "    X2 = np.array([[0] + Y[0:Ty-1]])\n",
        "    Y_soft = model.predict([X,X2] , batch_size=1)\n",
        "\n",
        "    return [Y_soft[0][i][Y[i]] for i in range(Ty)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(folder + \"Y_dev.csv\" , \"r\") as csvfile:\n",
        "  r = csv.reader(csvfile)\n",
        "  for i in range(0) : next(r)\n",
        "  T = [int(i) for i in next(r)]\n",
        "  print(\"Séquence de référence: \")\n",
        "  print(T)\n",
        "\n",
        "with open(folder + \"reversed_X_dev.csv\" , \"r\") as csvfile:\n",
        "  r = csv.reader(csvfile)\n",
        "  for i in range(0) : next(r)\n",
        "  seq = next(r)\n",
        "  T = beam_search([int(i) for i in seq] , 10)\n",
        "  print(\"Séquence inférée: \")\n",
        "  print(T)\n",
        "  T_soft = proba_a_posteriori([int(i) for i in seq] , 10)\n",
        "  print(\"Proba a posteriori de la séquence :\")\n",
        "  plt.plot(T_soft)"
      ],
      "metadata": {
        "id": "5K4aTTFCemIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_ZB1U8C6yRn"
      },
      "source": [
        "### Removing redundancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4HIm6ePphlQ"
      },
      "source": [
        "def beam_search_without_redundance(input_sequence , k):\n",
        "  # On utilise une entrée bidon pour nourir le modèle et obtenir le premier item\n",
        "  X2 = [0]*Ty\n",
        "  input_sequence = np.array([input_sequence])\n",
        "  # On cherche à savoir les différentes probabilité que le premier item soit acheté\n",
        "  Y = model.predict([input_sequence , np.array([X2])] , batch_size=1)\n",
        "  Y = [(Y[0][0][i] , i) for i in range(2,d)]\n",
        "  Y.sort(reverse = True)\n",
        "\n",
        "  K_best_candidates = []\n",
        "  for i in range(k):\n",
        "    score , item = Y[i]\n",
        "    K_best_candidates.append((score , [item]))\n",
        "\n",
        "  for i in range(1, Ty):\n",
        "    next_best_candidates = []\n",
        "    for candidat in K_best_candidates :\n",
        "      score , X2 = candidat\n",
        "      X = X2.copy() + [0]*(Ty - len(X2))\n",
        "      Y = model.predict( [input_sequence , np.array([X])] , batch_size=1)\n",
        "      Y = [(Y[0][i][j] , j) for j in range(1, d)]\n",
        "      Y.sort(reverse = True)\n",
        "      j = 0\n",
        "      a = 0\n",
        "      while a < k:\n",
        "        proba , item = Y[j]\n",
        "        if item not in X:\n",
        "          next_best_candidates.append((score*proba , X2.copy() + [item]))\n",
        "          a += 1\n",
        "        j += 1\n",
        "\n",
        "    next_best_candidates.sort(reverse= True)\n",
        "    K_best_candidates = next_best_candidates[0:k]\n",
        "\n",
        "  _ , infered_sequence = K_best_candidates[0]\n",
        "\n",
        "  return [item for item in infered_sequence]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(folder + \"Y_dev.csv\" , \"r\") as csvfile:\n",
        "  r = csv.reader(csvfile)\n",
        "  for i in range(0) : next(r)\n",
        "  T = [int(i) for i in next(r)]\n",
        "  print(\"Séquence de référence: \")\n",
        "  print(T)\n",
        "\n",
        "with open(folder + \"reversed_X_dev.csv\" , \"r\") as csvfile:\n",
        "  r = csv.reader(csvfile)\n",
        "  for i in range(0) : next(r)\n",
        "  seq = next(r)\n",
        "  T = beam_search([int(i) for i in seq] , 3)\n",
        "  print(\"Séquence inférée: \")\n",
        "  print(T)\n",
        "  T_diff = beam_search_without_redundance([int(i) for i in seq] , 3)\n",
        "  print(\"Séquence inférée sans redondance :\")\n",
        "  print(T_diff)\n",
        "\n",
        "  print(\"Historique :\")\n",
        "  print(seq)"
      ],
      "metadata": {
        "id": "ipgdVyAoesW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}