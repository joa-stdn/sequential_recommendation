{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DIh5BaQY9T_n",
        "DY3LyXmg4pGj",
        "ybMeLCSbXW8W",
        "Z6Ud2K67CBqg",
        "ptAdhYmlHTuo",
        "EaXZpSX7Hfhh",
        "SQ5fnPq3ouz9",
        "Lu72ly1lfA9K",
        "bxyp2Z3_rp1d",
        "M0TJU-2SgGfA",
        "gWNlURs2Ryfx",
        "pciEuMssZ8Ha"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L155ZitxUX19"
      },
      "source": [
        "# Designing a metric to compare baskets of items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpZh1ld_UjBK"
      },
      "source": [
        "The goal of this notebook is to create a metric comparing two unordered sets of items. It shall be based on structured data provided by the e-commerce platform, as well as basic natural language processing on product names.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIh5BaQY9T_n"
      },
      "source": [
        "## Loading CSV files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK-rh3P69T_n"
      },
      "source": [
        "import csv\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as clr\n",
        "import scipy.optimize\n",
        "import seaborn as sns\n",
        "from keras.layers import Dense, Activation, Input, Embedding, Flatten\n",
        "from keras.models import load_model, Model, Sequential\n",
        "from keras.utils import Sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhlG_58Vs4kq",
        "outputId": "ef6ed11e-8990-47b7-b5ea-9209efe4299b"
      },
      "source": [
        "from google.colab import drive # Il faut pouvoir lire les fichiers CSV du Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY3LyXmg4pGj"
      },
      "source": [
        "## Creating a dictionary with items as keys and available information on products as values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k_JVAF69T_o"
      },
      "source": [
        "filename1 = \"/content/drive/MyDrive/PSC Recommandation séquentielle/Données/DataTables/codtoID.csv\"\n",
        "filename2 = \"/content/drive/MyDrive/PSC Recommandation séquentielle/Données/Caractéristiques des produits : CodeBarre, Nom, SousClasse, Classe, Rayon, Marque/items.csv\"\n",
        "\n",
        "d1 = {}\n",
        "d2 = {}\n",
        "d2[0] = ['Vide'] * 6\n",
        "def fill_d2():\n",
        "  with open(filename1, newline='') as csvfile:\n",
        "    with open(filename2, newline='') as csvfile2:\n",
        "        spamreader = csv.reader(csvfile)\n",
        "        spamreader2 = csv.reader(csvfile2)\n",
        "        for row in spamreader:\n",
        "          d1[row[0]] = row[1] # cela correspond à temporairement d[codebarre] = id\n",
        "        l = d1.keys()\n",
        "        for row2 in spamreader2:\n",
        "          if row2[0] in l:\n",
        "            d2[int(d1[row2[0]])] = row2\n",
        "\n",
        "fill_d2()\n",
        "def infos(id):\n",
        "  return d2[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84MRGR3hwcq0"
      },
      "source": [
        "def codebarre(id):\n",
        "  return d2[id][0]\n",
        "\n",
        "def nom(id):\n",
        "  return d2[id][1]\n",
        "\n",
        "def sous_classe(id):\n",
        "  return d2[id][2]\n",
        "\n",
        "def classe(id):\n",
        "  return d2[id][3]\n",
        "\n",
        "def rayon(id):\n",
        "  return d2[id][4]\n",
        "\n",
        "def marque(id):\n",
        "  return d2[id][5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybMeLCSbXW8W"
      },
      "source": [
        "## Auxiliary functions on baskets and product classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmHaBA-zXi4c"
      },
      "source": [
        "def toText(panier): # un panier est une liste d'id (int)\n",
        "  l = []\n",
        "  for x in panier:\n",
        "    l.append(d2[x][1])\n",
        "  return l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcXE71m2jAvx"
      },
      "source": [
        "par_rayons_classes_sous_classes = {}\n",
        "def fillRayonsClassesSousClasses():\n",
        "  for id, l in d2.items():\n",
        "    if l[4] in par_rayons_classes_sous_classes.keys():\n",
        "      if l[3] in par_rayons_classes_sous_classes[l[4]].keys():\n",
        "        if l[2] in par_rayons_classes_sous_classes[l[4]][l[3]].keys():\n",
        "          par_rayons_classes_sous_classes[l[4]][l[3]][l[2]].append(id)\n",
        "        else:\n",
        "          par_rayons_classes_sous_classes[l[4]][l[3]][l[2]] = [id]\n",
        "      else:\n",
        "        par_rayons_classes_sous_classes[l[4]][l[3]] = {l[2]: [id]}\n",
        "    else:\n",
        "      par_rayons_classes_sous_classes[l[4]] = {l[3]: {l[2]: [id]}}\n",
        "\n",
        "fillRayonsClassesSousClasses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO_O_In2uJvw"
      },
      "source": [
        "def liste_rayons(): # C'est la liste des rayons\n",
        "  return list(par_rayons_classes_sous_classes.keys())\n",
        "\n",
        "def liste_classes(rayon): # Cela donne la liste des classes d'un rayon\n",
        "  return list(par_rayons_classes_sous_classes[rayon].keys())\n",
        "\n",
        "def liste_sous_classes(rayon, classe): # Cela donne la liste des sous-classes d'une classe d'un rayon\n",
        "  return list(par_rayons_classes_sous_classes[rayon][classe].keys())\n",
        "\n",
        "def liste_produits(rayon, classe, sous_classe): # Cela donne la liste des id d'une sous-classe d'une classe d'un rayon\n",
        "  return par_rayons_classes_sous_classes[rayon][classe][sous_classe]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Ud2K67CBqg"
      },
      "source": [
        "## Leveraging item embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De88SmpfCFBN"
      },
      "source": [
        "model_embedding_64 = load_model(\"/content/drive/MyDrive/PSC Recommandation séquentielle/Modèles/RNN/RNN_3_save\") # On charge l'embedding pré-entrainé\n",
        "weights_64 = model_embedding_64.get_weights()[0]\n",
        "n_products = len(weights_64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtK2rA3rD-G3"
      },
      "source": [
        "def dist_embeddings(i, j):\n",
        "  return np.linalg.norm(weights_64[i] - weights_64[j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0PINngtE-c-"
      },
      "source": [
        "def avg_dist_sous_classe(r1, c1, sc1, r2, c2, sc2): # r rayon, c classe, sc sous classe\n",
        "  l1 = liste_produits(r1, c1, sc1)\n",
        "  l2 = liste_produits(r2, c2, sc2)\n",
        "  assert(len(l1) > 0 and len(l2) > 0)\n",
        "  s = 0\n",
        "  for id1 in l1:\n",
        "    for id2 in l2:\n",
        "      s += dist_embeddings(id1, id2)\n",
        "  return s / (len(l1) * len(l2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptAdhYmlHTuo"
      },
      "source": [
        "## Optimization function taking as input a $\\verb|numpy array|$ $g$ representing a complete weighted bipartite $n \\times n$ graph, and returning a perfect matching of maximum weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgPvXeefHXv3"
      },
      "source": [
        "def optimize_hungarian(g):\n",
        "  row_ind, col_ind = scipy.optimize.linear_sum_assignment(g, True) # https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html\n",
        "  return col_ind, g[row_ind, col_ind].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaXZpSX7Hfhh"
      },
      "source": [
        "## Example with a simple similarity function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8K7FG5yHldi"
      },
      "source": [
        "def sim_simple(i, j): # fonction très simple, juste pour l'exemple\n",
        "  if (i == j): return 1\n",
        "  if sous_classe(i) == sous_classe(j): return .9\n",
        "  if classe(i) == classe(j): return .7\n",
        "  if rayon(i) == rayon(j): return .5\n",
        "  return 0 # rien n'est similaire, on ne regarde pas la marque ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVa5SmWWIdtr"
      },
      "source": [
        "def comparer(seq1, seq2, b = False):\n",
        "  n = len(seq1)\n",
        "  g = np.array([[sim_simple(seq1[i], seq2[j]) for j in range (n)] for i in range (n)])\n",
        "  l, sim = optimize_hungarian(g) # l correspond à une liste [l_0, ..., l_{n-1}] telle que pour tout i, l'item seq1[i] est affecté à l'item seq2[l[i]]. Et sim est le score global de similarité, entre 0 et n. Plus sim est proche de n, plus les deux séquences sont proches\n",
        "  if b: # b vaut True lorsque l'on veut afficher l'association bijective entre les deux séquences\n",
        "    print(toText(seq1))\n",
        "    print(toText(seq2))\n",
        "    for i in range (n):\n",
        "      print(nom(seq1[i]), \" <-> \", nom(seq2[l[i]]), \" sim = \", g[i][l[i]])\n",
        "  return sim / n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparer([2, 122, 152, 59, 45, 1, 89, 9, 321, 22, 125, 4, 3, 17, 257, 5], [8979, 8, 4, 883, 7574, 13, 59, 427, 5, 2514, 2085, 1137, 157, 172, 2505, 1], True)"
      ],
      "metadata": {
        "id": "Qxa3wrgzXUcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ5fnPq3ouz9"
      },
      "source": [
        "## Designing a similarity function between products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unTYPdAUo5e0"
      },
      "source": [
        "Here is the chosen example used as a baseline for a similarity function between products $i_1$ et $i_2$:\n",
        "\n",
        "\\\\\n",
        "$$\n",
        "sim(i_1,i_2)= \\left\\{\n",
        "    \\begin{array}{ll}\n",
        "       1 & \\mbox{if } i_1 \\text{ et } i_2\\text{ have same barcode, }  \\\\\n",
        "       r_{nom}(1+sim_{noms}) & \\mbox{if } i_1 \\text{ et } i_2  \\text{ have different brands,}\\\\\n",
        "       r_{cat}(1+ sim_{noms}) & \\mbox{if } i_1 \\text{ et } i_2  \\text{ have different classes,}\\\\\n",
        "       r_{ray}(1+sim_{noms}) & \\mbox{if } i_1 \\text{ et } i_2  \\text{ are in the same area.}\n",
        "    \\end{array}\n",
        "\\right.\n",
        "$$\n",
        " \\\\\n",
        " with $sim_{noms}=\\min \\left( \\frac{\\text{size of the longest common subsequence}}{\\text{min of sizes of sequences}}p, 1 \\right)$, where $p$ is a precision factor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PITqdlxqtQLG"
      },
      "source": [
        "r_nom=0.5\n",
        "r_ray=0.1\n",
        "r_cat=0.20\n",
        "p=3/2           #si la sous séquence commune est de taille supérieure à la 2/3 de la plus petite des deux séquences, on renvoie 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0z_JcxosXed"
      },
      "source": [
        "def simhard(i1, i2): # i1 et i2 correspondent au même produit (=0 si c'est un non-achat)\n",
        "  t1 = infos(i1)\n",
        "  t2 = infos(i2)\n",
        "  if (t1[0] == t2[0]): # alors ce sont les mêmes produits\n",
        "    return 1\n",
        "  if i1 == 0 or i2 == 0: # cas à la con\n",
        "    return 0\n",
        "  if t1[4] != t2[4]: # rayons différents\n",
        "    return 0\n",
        "  if t1[1] == t2[1]: #rayons identiques puisque sinon ça aurait déjà retourné 0 et même sous-classe\n",
        "      return (r_nom*(1+sim_noms(t1[1],t2[1],p)))\n",
        "  if t1[3]==t2[3]: #rayons identiques, même catégorie, mais sous classes différentes\n",
        "      return (r_cat*(1+sim_noms(t1[1],t2[1],p)))\n",
        "  return  (r_ray*(1+sim_noms(t1[1],t2[1],p))) # seulement le rayon est identique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu72ly1lfA9K"
      },
      "source": [
        "#### Similarity between strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQPrWSShSuoB"
      },
      "source": [
        "The following function is a dynamic programming with memoization implementation of a $O(mn)$ algorithm to compute the longest common subsequence between two input strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpXkGeXsSt1N"
      },
      "source": [
        "def LCSubStr(s1,s2,m,n):\n",
        "  #on cree le tableau qui stocke les LCSuff\n",
        "  LCStuff=np.zeros([m,n])\n",
        "  result=0\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      #la ligne 0 n'a pas de sens dans notre algo\n",
        "      if i==0 or j==0 :\n",
        "        LCStuff[i][j]=0\n",
        "      elif s1[i-1]==s2[j-1]:\n",
        "        LCStuff[i][j]=LCStuff[i-1][j-1]+1\n",
        "        if result<LCStuff[i][j]:\n",
        "          result=LCStuff[i][j]\n",
        "      else :\n",
        "        LCStuff[i][j]=0\n",
        "  return (result)\n",
        "\n",
        "def LCS(s1,s2):\n",
        "  return LCSubStr(s1,s2,len(s1),len(s2))\n",
        "\n",
        "def sim_noms(s1,s2,p):\n",
        "  return np.min([LCS(s1,s2)/np.min([len(s1),len(s2)])*p,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyp2Z3_rp1d"
      },
      "source": [
        "## Designing a similarity function between baskets of products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr0BwRhtIerr"
      },
      "source": [
        "def csv_to_table(file):\n",
        "  paniers=[]\n",
        "  with open(folder_res + file , \"r\") as csvfile:\n",
        "    r = csv.reader(csvfile)\n",
        "    T_ref=[]\n",
        "    for row in r:\n",
        "      if r.line_num%2!=0:\n",
        "        T_ref = [int(i) for i in row]\n",
        "      else:\n",
        "        T_inf =  [int(i) for i in row]\n",
        "        paniers.append([T_ref,T_inf])\n",
        " #print (paniers)\n",
        "  return(paniers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0TJU-2SgGfA"
      },
      "source": [
        "### Parameter initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BDle-VQrxCr"
      },
      "source": [
        "This section handles the initialization of hyperparameters to have a decent similarity between randomly chosen item baskets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z, lmbd = 16,  t = 0.3):\n",
        "  return 1/(1+np.exp(-(z-t)*lmbd))\n",
        "\n",
        "def filtre(z,lmbd=10, t=0.2):\n",
        "  if z<t:\n",
        "    return 0\n",
        "  else:\n",
        "    return (1-np.exp(-lmbd*(z-t)))/(1-np.exp(-lmbd*(1-t)))\n",
        "\n",
        "def afficherfiltre():\n",
        "  X=np.linspace(0,1,1000)\n",
        "  Y=[filtre(x) for x in X]\n",
        "  plt.plot(X,Y)\n",
        "\n",
        "def comparerhard(seq1, seq2, b = False):\n",
        "  n = len(seq1)\n",
        "  g = np.array([[simhard(seq1[i], seq2[j]) for j in range (n)] for i in range (n)])\n",
        "  l, sim = optimize_hungarian(g) # l correspond à une liste [l_0, ..., l_{n-1}] telle que pour tout i, l'item seq1[i] est affecté à l'item seq2[l[i]]. Et sim est le score global de similarité, entre 0 et n. Plus sim est proche de n, plus les deux séquences sont proches\n",
        "  if b: # b vaut True lorsque l'on veut afficher l'association bijective entre les deux séquences\n",
        "    print(toText(seq1))\n",
        "    print(toText(seq2))\n",
        "    for i in range (n):\n",
        "      print(nom(seq1[i]), \" <-> \", nom(seq2[l[i]]), \" sim = \", g[i][l[i]])\n",
        "  return filtre(sim / n)\n",
        "\n",
        "afficherfiltre()"
      ],
      "metadata": {
        "id": "az9ddFuDaD2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities=[]\n",
        "for i in range (1000):\n",
        "  panier1=np.random.randint(14370, size=16)\n",
        "  panier2=np.random.randint(14370, size=16)\n",
        "  similarities.append(comparerhard(panier1,panier2,False))\n",
        "print('Minimum des similarités:')\n",
        "print (np.min(similarities))\n",
        "print('Maximum des similarités:')\n",
        "print (np.max(similarities))\n",
        "print('Moyenne des similarités:')\n",
        "print (np.mean(similarities))\n",
        "ax=sns.displot(data=similarities, kde=True, bins=25, color='black')\n",
        "ax.set(xlabel=\"similarité\",ylabel=\"occurrences\", title=\"Distribution des similarités pour une centaine de bi paniers prédits avec k=10\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5jknW3q7ZIVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iu12pPAgMmG"
      },
      "source": [
        "## Evaluating models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWNlURs2Ryfx"
      },
      "source": [
        "### Influence of the beam size $k$ on evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def affichercourbesk(K=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,25,30,35,40,45,50,60,70],limit=1000):\n",
        "  #K=np.arange(1,21)\n",
        "  means=[]\n",
        "  firstquart=[]\n",
        "  dec40=[]\n",
        "  dec60=[]\n",
        "  lastquart=[]\n",
        "  meds=[]\n",
        "  #fig, axs = plt.subplots((len(K))//4+1, 4,squeeze=False)\n",
        "  #plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
        "  #j=0\n",
        "  for k in K:\n",
        "    #j+=1\n",
        "    file_res=\"Y_dev_k\"+str(k)+\".csv\"\n",
        "    paniers=csv_to_table(file_res)\n",
        "    sim=[]\n",
        "    for i in range(np.min([len(paniers),limit])):\n",
        "      sim.append(comparerhard(paniers[i][0], paniers[i][1],False))\n",
        "    print('--------------------------')\n",
        "    print('--------------------------')\n",
        "    print('RESULTAT POUR k='+str(k)+\":\")\n",
        "    print('--------------------------')\n",
        "    print('Minimum des similarités:')\n",
        "    print (np.min(sim))\n",
        "    print('Maximum des similarités:')\n",
        "    print (np.max(sim))\n",
        "    print('Moyenne des similarités:')\n",
        "    mean=np.mean(sim)\n",
        "\n",
        "    firstq=np.percentile(sim, 25)\n",
        "    dec4=np.percentile(sim,40)\n",
        "    med=np.percentile(sim,50)\n",
        "    dec6=np.percentile(sim,60)\n",
        "    lastq=np.percentile(sim,75)\n",
        "    firstquart.append(firstq)\n",
        "    means.append(mean)\n",
        "    dec40.append(dec4)\n",
        "    meds.append(med)\n",
        "    dec60.append(dec6)\n",
        "    lastquart.append(lastq)\n",
        "\n",
        "    print (mean)\n",
        "    print(' ')\n",
        "    #Si l'on veut afficher toutes les distributions:\n",
        "    #graph=sns.histplot(data=sim, kde=True, color='grey', bins=20,ax=axs[(j-1)//4, (j-1)%4])\n",
        "    #graph.set(xlabel=\"similarité\",ylabel=\"occurrences\",title='Distribution pour k=' +str(k))\n",
        "  plt.plot(K,means, color=\"blue\")\n",
        "  plt.plot(K,firstquart, color='purple')\n",
        "  plt.plot(K, lastquart, color='yellow')\n",
        "  plt.plot(K,dec40, color='orange')\n",
        "  plt.plot(K,meds, color='gray')\n",
        "  plt.plot(K,dec60, color=\"red\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "affichercourbesk()"
      ],
      "metadata": {
        "id": "Nk6P3cZlZciD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating on development sets"
      ],
      "metadata": {
        "id": "pciEuMssZ8Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comparaison_dev_test(K=[1,5,10,25],limit=1000):\n",
        "  means_dev=[]\n",
        "  means_test=[]\n",
        "  plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
        "\n",
        "  for k in K:\n",
        "    #notons où nous allons chercher les données\n",
        "    file_res_dev=\"Y_dev_k\"+str(k)+\".csv\"\n",
        "    file_res_test=\"Y_test_k\"+str(k)+\".csv\"\n",
        "    paniers_dev=csv_to_table(file_res_dev)\n",
        "    paniers_test=csv_to_table(file_res_test)\n",
        "\n",
        "    #créons nos deu\n",
        "    sim_dev=[]\n",
        "    sim_test=[]\n",
        "    for i in range(np.min([len(paniers_dev),limit])):\n",
        "      sim_dev.append(comparerhard(paniers_dev[i][0], paniers_dev[i][1],False))\n",
        "    for i in range(np.min([len(paniers_test),limit])):\n",
        "      sim_test.append(comparerhard(paniers_test[i][0], paniers_test[i][1],False))\n",
        "\n",
        "    #enregistrons les valeurs moyennes\n",
        "    mean_dev=np.mean(sim_dev)\n",
        "    mean_test=np.mean(sim_test)\n",
        "    means_dev.append(mean_dev)\n",
        "    means_test.append(mean_test)\n",
        "  plt.plot(K,means_dev, color=\"blue\")\n",
        "  plt.plot(K,means_test, color=\"green\")\n",
        "  plt.show()\n",
        "\n",
        "comparaison_dev_test()"
      ],
      "metadata": {
        "id": "CTO09iQlZoQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distribCNN(limit=1000):\n",
        "  file_res=\"Y_dev_CNN.csv\"\n",
        "  paniers=csv_to_table(file_res)\n",
        "  sim=[]\n",
        "  for i in range(np.min([len(paniers),limit])):\n",
        "    sim.append(comparerhard(paniers[i][0], paniers[i][1],False))\n",
        "  print('--------------------------')\n",
        "  print('--------------------------')\n",
        "  print('RESULTATS CNN dev')\n",
        "  print('--------------------------')\n",
        "  print('Minimum des similarités:')\n",
        "  print (np.min(sim))\n",
        "  print('Maximum des similarités:')\n",
        "  print (np.max(sim))\n",
        "  print('Moyenne des similarités:')\n",
        "  print (np.mean(sim))\n",
        "  print(' ')\n",
        "  plt.figure(figsize=(10,10))\n",
        "  graph=sns.histplot(data=sim, kde=True, color='green', bins=40)\n",
        "  graph.set(xlabel=\"similarité\",ylabel=\"occurrences\",title=\"Resultat pour CNN\")\n",
        "\n",
        "\n",
        "  file_res=\"Y_test_CNN.csv\"\n",
        "  paniers=csv_to_table(file_res)\n",
        "  sim=[]\n",
        "  for i in range(np.min([len(paniers),limit])):\n",
        "    sim.append(comparerhard(paniers[i][0], paniers[i][1],False))\n",
        "  print('--------------------------')\n",
        "  print('--------------------------')\n",
        "  print('RESULTATS CNN test')\n",
        "  print('--------------------------')\n",
        "  print('Minimum des similarités:')\n",
        "  print (np.min(sim))\n",
        "  print('Maximum des similarités:')\n",
        "  print (np.max(sim))\n",
        "  print('Moyenne des similarités:')\n",
        "  print (np.mean(sim))\n",
        "  print(' ')\n",
        "  graph=sns.histplot(data=sim, kde=True, color='blue', bins=40)\n",
        "  graph.set(xlabel=\"similarité\",ylabel=\"occurrences\",title=\"Resultat pour CNN\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kIa9iYPWZw7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}